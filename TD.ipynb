{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msystem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     states,\n\u001b[0;32m      5\u001b[0m     actions, \n\u001b[0;32m      6\u001b[0m     wind_col,\n\u001b[0;32m      7\u001b[0m     num_states,\n\u001b[0;32m      8\u001b[0m     num_actions,\n\u001b[0;32m      9\u001b[0m     init_mdp,\n\u001b[0;32m     10\u001b[0m     init_reward,\n\u001b[0;32m     11\u001b[0m     to_idx,\n\u001b[0;32m     12\u001b[0m     to_state,\n\u001b[0;32m     13\u001b[0m     get_valid_actions,\n\u001b[0;32m     14\u001b[0m     gen_random_sa,\n\u001b[0;32m     15\u001b[0m     rows,\n\u001b[0;32m     16\u001b[0m     cols\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolicy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Policy, PolicyInit\n",
      "File \u001b[1;32md:\\BTech\\Sem8\\Topics in RL\\RL-Project-1\\system.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# System description\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# States: grid coordinates\u001b[39;00m\n\u001b[0;32m      7\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from system import (\n",
    "    states,\n",
    "    actions, \n",
    "    wind_col,\n",
    "    num_states,\n",
    "    num_actions,\n",
    "    init_mdp,\n",
    "    init_reward,\n",
    "    to_idx,\n",
    "    to_state,\n",
    "    get_valid_actions,\n",
    "    gen_random_sa,\n",
    "    rows,\n",
    "    cols\n",
    ")\n",
    "from model import Model\n",
    "from policy import Policy, PolicyInit\n",
    "from agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch_egreedy(epsilon, Q, s):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.choice(get_valid_actions(to_state(s)))\n",
    "    else:\n",
    "        return np.argmax(Q[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = init_mdp(num_states, num_actions, wind_col)\n",
    "reward = init_reward(num_states, t_reward=100)\n",
    "model = Model(mdp, reward)\n",
    "\n",
    "policy = Policy(num_states, num_actions, PolicyInit.RANDOM)\n",
    "\n",
    "agent = Agent(model, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_val = np.random.uniform(-10, -1, (num_states, num_actions))\n",
    "for a in range(num_actions):\n",
    "    Q_val[37][a] = 0\n",
    "# Q_val = np.zeros((num_states, num_actions))\n",
    "returns = [[[] for a in range(num_actions)] for s in range(num_states)]\n",
    "valf_list = [(np.max(Q_val, axis=1))]\n",
    "\n",
    "i = 0\n",
    "T = 1000\n",
    "gamma = 0.9\n",
    "alpha = 0.1\n",
    "while i < 1000:\n",
    "    start_state = 30\n",
    "    start_action = ch_egreedy(0.1, Q_val, start_state)\n",
    "    state = start_state\n",
    "    action = start_action\n",
    "    while state != 37:\n",
    "        r = model.reward(state, action)\n",
    "        nstate = model.gen_next(state, action)\n",
    "        naction = ch_egreedy(0.1, Q_val, nstate)\n",
    "        Q_val[state, action] = Q_val[state, action] + alpha * (r + gamma * Q_val[nstate][naction] - Q_val[state, action])\n",
    "        state = nstate\n",
    "        action = naction\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valf = valf_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "valf_toplot = valf.reshape(rows, cols)\n",
    "plt.gca().invert_yaxis()\n",
    "heatmap = plt.imshow(valf_toplot)\n",
    "plt.colorbar(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run agent\n",
    "score = 0\n",
    "steps = 0\n",
    "s = np.array([3,0])\n",
    "\n",
    "path = [s]\n",
    "\n",
    "while(steps < 1000):\n",
    "    a = policy.get_action(s)\n",
    "\n",
    "    s_ = model.gen_next(s, a)\n",
    "    path.append(s_)\n",
    "\n",
    "    r = model.get_reward(s, s_)\n",
    "    score += r\n",
    "    print(f\"State: {s}, Action: {actions[a]}, Next State: {s_}, Reward: {r}\")\n",
    "\n",
    "    if(r!= -1):\n",
    "        print(f\"Game Over - Score: {score}\")\n",
    "        break\n",
    "    \n",
    "    s = s_\n",
    "    steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_plt = np.array(path) + 0.5\n",
    "y, x = path_plt.T\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.grid()\n",
    "\n",
    "ax.set_xlim(0, cols)\n",
    "ax.set_xticks(np.arange(0, cols, 1), minor=False)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xticks(np.arange(0.5, cols, 1), minor=True)\n",
    "ax.set_xticklabels([str(x) for x in wind_col], minor=True)\n",
    "\n",
    "ax.set_ylim(rows, 0)\n",
    "ax.set_yticks(np.arange(0, rows, 1), minor=False)\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "ax.plot(x, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

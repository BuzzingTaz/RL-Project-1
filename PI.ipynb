{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from system import (\n",
    "    mdp,\n",
    "    reward,\n",
    "    states,\n",
    "    num_states,\n",
    "    num_actions,\n",
    "    to_idx,\n",
    "    get_valid_actions,\n",
    ")\n",
    "from model import Model\n",
    "from policy import Policy, PolicyInit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluatePolicy(\n",
    "    policy: Policy, valf: np.ndarray, model: Model, thresh=0.01, gamma=1.0\n",
    "):\n",
    "    i = 0\n",
    "    delta = thresh + 1\n",
    "    while delta > thresh and i < 1000:\n",
    "        delta = 0\n",
    "        for s in states:\n",
    "            v = valf[to_idx(s)]\n",
    "            a = policy.get_action(s)\n",
    "            # policy.set_action(to_state(s), a)\n",
    "\n",
    "            valf[to_idx(s)] = model.prob(s, a) @ (model.get_reward(s) + gamma * valf)\n",
    "\n",
    "            delta = max(delta, abs(v - valf[to_idx(s)]))\n",
    "        i += 1\n",
    "    return valf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdatePolicy(policy: Policy, valf: np.ndarray, model: Model, gamma=1.0):\n",
    "    policy_stable = True\n",
    "    k = 0\n",
    "    for s in states:\n",
    "        old_action = policy.get_action(s)\n",
    "        amzt = np.argmax(\n",
    "            [\n",
    "                model.prob(s, a) @ (model.get_reward(s) + gamma * valf)\n",
    "                for a in get_valid_actions(s, idx=True)\n",
    "            ]\n",
    "        )\n",
    "        amzt = get_valid_actions(s, idx=True)[amzt]\n",
    "        policy.set_action(s, amzt)\n",
    "        if old_action != policy.get_action(s):\n",
    "            k+=1\n",
    "            policy_stable = False\n",
    "    print(f\"Policy changed for {k} states\")\n",
    "    return policy_stable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = Model(mdp, reward)\n",
    "\n",
    "# Initialize policy\n",
    "policy = Policy(num_states, num_actions, PolicyInit.RANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in states:\n",
    "    policy.set_action(s, policy.gen_action_idx(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Iteration 1\n",
      "Evaluating Policy\n",
      "Updating Policy\n",
      "Policy changed for 59 states\n",
      "Policy Iteration 2\n",
      "Evaluating Policy\n",
      "Updating Policy\n",
      "Policy changed for 39 states\n",
      "Policy Iteration 3\n",
      "Evaluating Policy\n",
      "Updating Policy\n",
      "Policy changed for 29 states\n",
      "Policy Iteration 4\n",
      "Evaluating Policy\n",
      "Updating Policy\n",
      "Policy changed for 18 states\n",
      "Policy Iteration 5\n",
      "Evaluating Policy\n",
      "Updating Policy\n",
      "Policy changed for 18 states\n",
      "Policy Iteration 6\n",
      "Evaluating Policy\n",
      "Updating Policy\n",
      "Policy changed for 12 states\n",
      "Policy Iteration 7\n",
      "Evaluating Policy\n",
      "Updating Policy\n",
      "Policy changed for 8 states\n",
      "Policy Iteration 8\n",
      "Evaluating Policy\n",
      "Updating Policy\n",
      "Policy changed for 4 states\n",
      "Policy Iteration 9\n",
      "Evaluating Policy\n",
      "Updating Policy\n",
      "Policy changed for 1 states\n",
      "Policy Iteration 10\n",
      "Evaluating Policy\n",
      "Updating Policy\n",
      "Policy changed for 0 states\n"
     ]
    }
   ],
   "source": [
    "# Initialize random state function\n",
    "valf = np.random.uniform(0, 2, size=num_states)\n",
    "valf_store = []\n",
    "valf_store.append(valf)\n",
    "\n",
    "thresh = 0.01\n",
    "gamma = 0.9\n",
    "\n",
    "policy_stable = False\n",
    "i = 0\n",
    "while (not policy_stable) and i < 1000:\n",
    "    print(f\"Policy Iteration {i + 1}\")\n",
    "\n",
    "    # Policy Evaluation\n",
    "    print(\"Evaluating Policy\")\n",
    "    valf = EvaluatePolicy(policy, valf, model, thresh, gamma)\n",
    "    valf_store.append(valf)\n",
    "\n",
    "    # Policy Improvement\n",
    "    print(\"Updating Policy\")\n",
    "    policy_stable = UpdatePolicy(policy, valf, model, gamma)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: [3 5] Action: 7\n",
      "Next State: [3 6]\n",
      "Reward: -1\n",
      "State: [3 6] Action: 7\n",
      "Next State: [0 7]\n",
      "Reward: -1\n",
      "State: [0 7] Action: 7\n",
      "Next State: [1 8]\n",
      "Reward: -1\n",
      "State: [1 8] Action: 7\n",
      "Next State: [2 9]\n",
      "Reward: -1\n",
      "State: [2 9] Action: 6\n",
      "Next State: [3 9]\n",
      "Reward: -1\n",
      "State: [3 9] Action: 6\n",
      "Next State: [4 9]\n",
      "Reward: -1\n",
      "State: [4 9] Action: 6\n",
      "Next State: [5 9]\n",
      "Reward: -1\n",
      "State: [5 9] Action: 5\n",
      "Next State: [5 8]\n",
      "Reward: -1\n",
      "State: [5 8] Action: 5\n",
      "Next State: [3 7]\n",
      "Reward: 10\n",
      "Game Over - Score: 2\n"
     ]
    }
   ],
   "source": [
    "# Run agent\n",
    "score = 0\n",
    "steps = 0\n",
    "s = np.array([3,5])\n",
    "\n",
    "path = [s]\n",
    "\n",
    "while(True):\n",
    "    a = policy.get_action(s)\n",
    "    print(f\"State: {s} Action: {a}\")\n",
    "\n",
    "    s_ = model.gen_next(s, a)\n",
    "    path.append(s_)\n",
    "    print(f\"Next State: {s_}\")\n",
    "\n",
    "    reward = model.get_reward(s, s_)\n",
    "    score += reward\n",
    "    print(f\"Reward: {reward}\")\n",
    "\n",
    "    if(reward != -1):\n",
    "        print(f\"Game Over - Score: {score}\")\n",
    "        break\n",
    "    \n",
    "    s = s_\n",
    "    steps += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
